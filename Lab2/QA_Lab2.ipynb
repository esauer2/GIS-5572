{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "import os\n",
    "import io\n",
    "import zipfile\n",
    "import shapefile\n",
    "from shapely.geometry import Point, shape\n",
    "from shapely import geometry\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import fiona\n",
    "from fiona.crs import from_epsg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir(r'E:\\ArcGIS_2\\Lab2')\n",
    "wksp = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull weather information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 153 weather stations of the Minnesota network selecting a random day\n",
    "link = r'https://mesonet.agron.iastate.edu/api/1/daily.geojson?date=2023-03-15&network=MN_RWIS'\n",
    "info = json.loads(requests.get(link).text)\n",
    "location = []\n",
    "for i in range(len(info['features'])):\n",
    "    # Store the station and its coordinates\n",
    "    location.append({'station': info['features'][i]['properties']['station'], \n",
    "                     'coordinates': info['features'][i]['geometry']['coordinates']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Daily weather data from 2023\n",
    "url = r'https://mesonet.agron.iastate.edu/api/1/daily.geojson?network=MN_RWIS&year=2023'\n",
    "weather = json.loads(requests.get(url).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Delete all the unneeded weather variables and keep only minimum and maximum temperature\n",
    "delete = [\n",
    "      \"tmpf_est\",\n",
    "      \"precip\",\n",
    "      \"precip_est\",\n",
    "      \"max_gust\",\n",
    "      \"snow\",\n",
    "      \"snowd\",\n",
    "      \"min_rh\",\n",
    "      \"max_rh\",\n",
    "      \"min_dwpf\",\n",
    "      \"max_dwpf\",\n",
    "      \"min_feel\",\n",
    "      \"max_feel\",\n",
    "      \"min_rstage\",\n",
    "      \"max_rstage\",\n",
    "      \"temp_hour\",\n",
    "      \"max_gust_localts\",\n",
    "      \"max_drct\",\n",
    "      \"avg_feel\", \n",
    "      \"avg_sknt\", \n",
    "      \"vector_avg_drct\", \n",
    "      \"id\"\n",
    "]\n",
    "\n",
    "for i in range(len(weather['features'])):\n",
    "    for key in delete:\n",
    "        del weather['features'][i]['properties'][key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull Minnesota boundary from MGC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, March 15, 2023 8:10:00 PM\",\"Succeeded at Wednesday, March 15, 2023 8:10:01 PM (Elapsed Time: 0.79 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'E:\\\\ArcGIS_2\\\\Lab2\\\\minnesota.shp'>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MN boundary\n",
    "mn_url = \"https://resources.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_dot/bdry_state/shp_bdry_state.zip\"\n",
    "boundaries = requests.post(mn_url)\n",
    "zipfile.ZipFile(io.BytesIO(boundaries.content)).extractall(wksp)\n",
    "\n",
    "# Project shp\n",
    "sr = arcpy.SpatialReference(4326)\n",
    "arcpy.Project_management('Boundaries_of_Minnesota.shp', 'minnesota.shp', sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ranges_intersect(range1, range2):\n",
    "    \"\"\"\n",
    "    Returns True if the two ranges intersect, False otherwise.\n",
    "    Each range is a tuple of two numbers representing the minimum and maximum values of the range.\n",
    "    \"\"\"\n",
    "    if range1[1] < range2[0] or range2[1] < range1[0]:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the optimum range is 62-99 F, but a different range is used to train the code as the temperature recorded for 2023 is still below the optimum range due to the winter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Optimum temperature\n",
    "lower_temp = 10 #62\n",
    "upper_temp = 50 #99\n",
    "opt_temp = range(lower_temp, upper_temp+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the shapefile data for Minnesota\n",
    "sf = shapefile.Reader(\"minnesota.shp\")\n",
    "shapes = sf.shapes()\n",
    "state_border = shapes[0]\n",
    "\n",
    "# Create a shapely Polygon object from the state border shape\n",
    "border_polygon = shape(state_border)\n",
    "\n",
    "# Create an empty list to add the not useful readings\n",
    "wrong = []\n",
    "\n",
    "# Add all the not useful readings to a list\n",
    "for i in range(len(weather['features'])):\n",
    "    \n",
    "    # Readings whose temp readings are None\n",
    "    if weather['features'][i]['properties']['min_tmpf'] == None or weather['features'][i]['properties']['max_tmpf'] == None:\n",
    "        wrong.append(weather['features'][i])\n",
    "        continue\n",
    "    \n",
    "    # Stations outside of Minnesota\n",
    "    point = Point(weather['features'][i]['geometry']['coordinates'])\n",
    "    if not border_polygon.contains(point):\n",
    "        wrong.append(weather['features'][i])\n",
    "        continue\n",
    "        \n",
    "    # Readings whose min and max temp are the same. This is an indicator of wrong data\n",
    "    if weather['features'][i]['properties']['min_tmpf'] == weather['features'][i]['properties']['max_tmpf']:\n",
    "        wrong.append(weather['features'][i])\n",
    "        continue\n",
    "        \n",
    "    # Readings whose temp is outside of the optimum range\n",
    "    lower_limit = math.floor(weather['features'][i]['properties']['min_tmpf'])\n",
    "    upper_limit = math.ceil(weather['features'][i]['properties']['max_tmpf'])\n",
    "    range_temp = range(lower_limit, upper_limit)\n",
    "    \n",
    "    # Readings not representative of the broader region if max and min temp are similar\n",
    "    if len(range_temp) == 1:\n",
    "        wrong.append(weather['features'][i]) \n",
    "        continue\n",
    "    \n",
    "# Delete the not useful readings \n",
    "for element in wrong:\n",
    "    weather['features'].remove(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly average temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[30]:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "stations = []\n",
    "# Add the dictionaries to a data frame\n",
    "for j in range(len(weather['features'])):\n",
    "    stations.append(weather['features'][j]['properties'])\n",
    "df = pd.DataFrame.from_dict(stations)\n",
    "\n",
    "# Remove the day part from the date leaving only year and month\n",
    "for i in range(len(df['date'])):\n",
    "    df['date'][i] = df['date'][i][:7]\n",
    "    \n",
    "# Get monthly average min and max temperature for each station\n",
    "grouped = df.groupby(['station', 'date', 'name']).agg('mean')\n",
    "grouped.reset_index(inplace=True)\n",
    "\n",
    "# Return data to a dictionary\n",
    "mean = grouped.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add the geometry to the stations\n",
    "mean_tmp = []\n",
    "for i in range(len(mean)):\n",
    "    for j in range(len(location)):\n",
    "        if mean[i]['station'] == location[j]['station']:\n",
    "            mean_tmp.append({'type': 'Feature', 'properties': mean[i], \n",
    "                             'geometry': {'type': 'Point', 'coordinates': location[j]['coordinates']}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove monthly average temperature if outside of the optimum range\n",
    "bad_data = []\n",
    "for i in range(len(mean_tmp)):\n",
    "    lower_limit = math.floor(mean_tmp[i]['properties']['min_tmpf'])\n",
    "    upper_limit = math.ceil(mean_tmp[i]['properties']['max_tmpf'])\n",
    "    range_temp = range(lower_limit, upper_limit)\n",
    "    # Temperature outside the optimum range is flagged\n",
    "    if ranges_intersect(opt_temp, range_temp) == False:\n",
    "        bad_data.append(mean_tmp[i])\n",
    "        \n",
    "# Delete the not useful readings \n",
    "for element in bad_data:\n",
    "    mean_tmp.remove(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stations shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema =  {'geometry': 'Point', 'properties': {'station': 'str', 'date': 'str', 'name': 'str', 'max_tmpf': 'float', 'min_tmpf': 'float'}}\n",
    "\n",
    "with fiona.open(\"stations.shp\", 'w', crs = from_epsg(4326), driver = 'ESRI Shapefile', schema = schema) as output:\n",
    "    for i in range(len(mean_tmp)):\n",
    "          # geometry\n",
    "          point = Point(mean_tmp[i]['geometry']['coordinates'])\n",
    "          # attributes\n",
    "          prop = mean_tmp[i]['properties']\n",
    "          # write the row (geometry + attributes in GeoJSON format)\n",
    "          output.write({'geometry': geometry.mapping(point), 'properties':prop})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve DEM from MGC\n",
    "dem_output = requests.post(r'https://resources.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_dnr/elev_30m_digital_elevation_model/fgdb_elev_30m_digital_elevation_model.zip')\n",
    "zipfile.ZipFile(io.BytesIO(dem_output.content)).extractall(wksp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, March 15, 2023 5:41:19 PM\",\"Building Pyramids...\",\"Calculating Statistics...\",\"Succeeded at Wednesday, March 15, 2023 5:41:50 PM (Elapsed Time: 30.78 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'E:\\\\ArcGIS_2\\\\Lab2\\\\DEM.tif'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.path.join(wksp, 'DEM.tif')\n",
    "\n",
    "arcpy.management.CopyRaster(\n",
    "    in_raster=r'/elev_30m_digital_elevation_model.gdb/digital_elevation_model_30m',\n",
    "    out_rasterdataset=path,\n",
    "    config_keyword=\"\",\n",
    "    background_value=None,\n",
    "    nodata_value=\"32767\",\n",
    "    onebit_to_eightbit=\"NONE\",\n",
    "    colormap_to_RGB=\"NONE\",\n",
    "    pixel_type=\"\",\n",
    "    scale_pixel_value=\"NONE\",\n",
    "    RGB_to_Colormap=\"NONE\",\n",
    "    format=\"TIFF\",\n",
    "    transform=\"NONE\",\n",
    "    process_as_multidimensional=\"CURRENT_SLICE\",\n",
    "    build_multidimensional_transpose=\"NO_TRANSPOSE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spatial Reference of DEM:  NAD_1983_UTM_Zone_15N\n",
      "Cell Size of DEM: 30.0 x 30.0\n",
      "Nodata values found in DEM\n",
      "Minimum elevation value in DEM is correct\n",
      "Maximum elevation value in DEM is correct\n"
     ]
    }
   ],
   "source": [
    "# Set input DEM\n",
    "dem = \"DEM.tif\"\n",
    "\n",
    "# Check the spatial reference of the DEM\n",
    "desc = arcpy.Describe(dem)\n",
    "sr = desc.spatialReference\n",
    "print(\"Spatial Reference of DEM: \", sr.name)\n",
    "\n",
    "# Check the cell size of the DEM\n",
    "cellSizeX = desc.meanCellWidth\n",
    "cellSizeY = desc.meanCellHeight\n",
    "print(\"Cell Size of DEM: {} x {}\".format(cellSizeX, cellSizeY))\n",
    "\n",
    "# Check for any nodata values in the DEM\n",
    "nodata = arcpy.sa.SetNull(dem, dem, \"VALUE = {}\".format(desc.noDataValue))\n",
    "if arcpy.management.GetRasterProperties(nodata, \"MAXIMUM\") == 0:\n",
    "    print(\"No nodata values found in DEM\") # This is expected due since MN isn't a rectangle\n",
    "else:\n",
    "    print(\"Nodata values found in DEM\")\n",
    "\n",
    "# Check the minimum and maximum elevation values in the DEM\n",
    "highest_point = [2301-50, 2301+50]\n",
    "lowest_point = [602-50, 602+50]\n",
    "\n",
    "minimum = int(arcpy.management.GetRasterProperties(dem, \"MINIMUM\").getOutput(0))\n",
    "maximum = int(arcpy.management.GetRasterProperties(dem, \"MAXIMUM\").getOutput(0))\n",
    "\n",
    "if minimum >= lowest_point[0] and minimum <= lowest_point[1]:\n",
    "    print(\"Minimum elevation value in DEM is correct\")\n",
    "else:\n",
    "    print(f\"Minimum elevation value in DEM is {minimum} and should be close to {lowest_point}\")\n",
    "    \n",
    "if maximum >= highest_point[0] and maximum <= highest_point[1]:\n",
    "    print(\"Maximum elevation value in DEM is correct\")\n",
    "else:\n",
    "    print(f\"Maximum elevation value in DEM is {maximum} and should be close to {highest_point}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, March 16, 2023 5:37:26 PM\",\"Succeeded at Thursday, March 16, 2023 5:38:09 PM (Elapsed Time: 43.06 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'E:\\\\ArcGIS_2\\\\Lab2\\\\DEM_projected.tif'>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Project DEM to WGS 1984\n",
    "sr = arcpy.SpatialReference(4326)\n",
    "output = os.path.join(wksp, 'DEM_projected.tif')\n",
    "arcpy.ProjectRaster_management(dem, output, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, March 16, 2023 8:17:16 PM\",\"Building Pyramids...\",\"Succeeded at Thursday, March 16, 2023 8:17:21 PM (Elapsed Time: 5.03 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'E:\\\\ArcGIS_2\\\\Lab2\\\\DEM_resampled.tif'>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Increase the cell size \n",
    "arcpy.management.Resample(\n",
    "    in_raster=\"DEM_projected.tif\",\n",
    "    out_raster=os.path.join(wksp, 'DEM_resampled.tif'),\n",
    "    cell_size=\"0.03 0.03\",\n",
    "    resampling_type=\"MAJORITY\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, March 16, 2023 8:16:58 PM\",\"Succeeded at Thursday, March 16, 2023 8:17:00 PM (Elapsed Time: 2.04 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'E:\\\\ArcGIS_2\\\\Lab2\\\\elevation.shp'>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create elevation points from DEM\n",
    "arcpy.conversion.RasterToPoint(\n",
    "    in_raster=\"DEM_resampled.tif\",\n",
    "    out_point_features=os.path.join(wksp, 'elevation.shp'),\n",
    "    raster_field=\"Value\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Land Cover Data QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\eriks\\OneDrive\\Documents\\ArcGIS\\Projects\\Arc2_Lab2')\n",
    "arcpy.env.workspace = r'C:\\Users\\eriks\\OneDrive\\Documents\\ArcGIS\\Projects\\Arc2_Lab2'\n",
    "wksp = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve Land Cover Data\n",
    "lcover_url = \"https://resources.gisdata.mn.gov/pub/gdrs/data/pub/edu_umn/base_landcover_minnesota/tif_base_landcover_minnesota.zip\"\n",
    "lcover_data = requests.get(lcover_url, verify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipfile.ZipFile(io.BytesIO(lcover_data.content)).extractall(wksp)\n",
    "lcover = \"landcover_impervious_statewide2013_v2.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcover_lyr = arcpy.MakeRasterLayer_management(lcover, \"Land Cover MN\")\n",
    "\n",
    "# Build pyramids\n",
    "arcpy.BuildPyramids_management(lcover_lyr)\n",
    "\n",
    "# Calculate statistics\n",
    "arcpy.CalculateStatistics_management(lcover_lyr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify Source Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the source file and data type\n",
    "arcpy.Describe(lcover_lyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the Raster layer to dataset for extracting properties\n",
    "lcover_dataset = \"lcover_dataset.tif\"\n",
    "arcpy.CopyRaster_management(lcover_lyr, lcover_dataset)\n",
    "arcpy.management.GetRasterProperties(lcover_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify Data is within MN boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MN boundary\n",
    "mn_url = \"https://resources.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_dot/bdry_state/shp_bdry_state.zip\"\n",
    "boundaries = requests.post(mn_url)\n",
    "zipfile.ZipFile(io.BytesIO(boundaries.content)).extractall(wksp)\n",
    "\n",
    "# Set spatial reference and add layer\n",
    "sr = arcpy.SpatialReference(4326)\n",
    "boundary = arcpy.Project_management('Boundaries_of_Minnesota.shp', 'minnesota.shp', sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get shapefile extent\n",
    "with arcpy.da.SearchCursor(boundary , ['SHAPE@']) as cursor:\n",
    "    for row in cursor:\n",
    "        shape_extent = row[0].extent\n",
    "\n",
    "# Extract raster cells within shapefile extent\n",
    "out_raster = arcpy.sa.ExtractByMask(lcover_dataset, boundary)\n",
    "\n",
    "# Check if all pixels are within the boundary\n",
    "result = arcpy.GetRasterProperties_management(out_raster, \"MAXIMUM\")\n",
    "max_val = float(result.getOutput(0))\n",
    "\n",
    "if max_val > 0:\n",
    "    print(\"All pixels are within the boundary.\")\n",
    "else:\n",
    "    print(\"There are pixels outside the boundary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for missing or incorrect values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raster file\n",
    "ds = gdal.Open('\"lcover_dataset.tif\"')\n",
    "band = ds.GetRasterBand(1)\n",
    "\n",
    "# Read the raster data as a numpy array\n",
    "data = band.ReadAsArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "if np.any(np.isnan(data)):\n",
    "    print('There are missing values in the raster.')\n",
    "\n",
    "# Check for negative values\n",
    "if np.any(data < 0):\n",
    "    print('There are negative values in the raster.')\n",
    "\n",
    "# Check the nodata value\n",
    "nodata = band.GetNoDataValue()\n",
    "if nodata is None:\n",
    "    print('There is no nodata value set for the raster.')\n",
    "else:\n",
    "    print(f'The nodata value is {nodata}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample raster for polygon conversion\n",
    "# Set cell size of output raster\n",
    "cell_size = 30\n",
    "\n",
    "# Resample raster to lower resolution\n",
    "lcover_resample = arcpy.Resample_management(lcover_lyr, \"lcov_resample\", cell_size, \"NEAREST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert rasterfile to polygon for pgAdmin\n",
    "arcpy.RasterToPolygon_conversion(lcover_resample,\"lcover_polygon\",\"SIMPLIFY\", \"Value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stinkbug Data QA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Acquisition and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve Stinkbugs Data\n",
    "sbug_url = \"https://resources.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_mda/biota_bmsb/shp_biota_bmsb.zip\"\n",
    "sbug_data = requests.get(sbug_url, verify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipfile.ZipFile(io.BytesIO(sbug_data.content)).extractall(wksp)\n",
    "sbug = \"BMSBSurveyDataTable.dbf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aprx = arcpy.mp.ArcGISProject(\"CURRENT\")\n",
    "aprxMap = aprx.listMaps(\"Map\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stinkbug data table\n",
    "sbugtable = arcpy.TableToTable_conversion(sbug, wksp, \"sbugtable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create point layer of data table\n",
    "x_field = \"Longitude\"\n",
    "y_field = \"Latitude\"\n",
    "output_fc = \"sbug_points\"\n",
    "spatial_reference = arcpy.SpatialReference(4326)\n",
    "sbug_points = arcpy.management.XYTableToPoint(sbugtable, output_fc, x_field, y_field, \"\", spatial_reference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify Points are within Minnesota Boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run intersect tool on points and MN boundary\n",
    "intersect = arcpy.Intersect_analysis([sbug_points, boundary], \"point_intersect.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select points that fall within the boundary of Minnesota and create new layer\n",
    "arcpy.MakeFeatureLayer_management(sbug_points, \"points_lyr\")\n",
    "selected_points = arcpy.SelectLayerByLocation_management(\"points_lyr\", \"INTERSECT\", boundary)\n",
    "MN_sbugpoints = arcpy.CopyFeatures_management(\"points_lyr\", \"intersect_sbug_points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = arcpy.GetCount_management(MN_sbugpoints)\n",
    "count = int(result.getOutput(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify resulting layer only includes points within MN boundary\n",
    "total_points = int(arcpy.GetCount_management(MN_sbugpoints).getOutput(0))\n",
    "if count == total_points:\n",
    "    print(\"All points are within the boundary of Minnesota.\")\n",
    "else:\n",
    "    print(\"Some points are outside the boundary of Minnesota.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify observations are within acceptable range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set acceptable count range\n",
    "range = [0, 10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists to store invalid and valid observations\n",
    "invalid_observations = []\n",
    "valid_observations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for valid/invalid observations and append them to their respective lists\n",
    "with arcpy.da.SearchCursor(MN_sbugpoints, [\"Adults\", \"Nymphs\"]) as cursor:\n",
    "    for row in cursor:\n",
    "        if row[0] >= range[0] and row[0] <= range[1]:\n",
    "            # Add the valid observation to the list\n",
    "            valid_observations.append(row)\n",
    "            \n",
    "            if row[1] >= range[0] and row[1] <= range[1]:\n",
    "                # Add the valid observation to the list\n",
    "                valid_observations.append(row)\n",
    "            else:\n",
    "                # Add the invalid observation to the list\n",
    "                invalid_observations.append(row)\n",
    "                \n",
    "        else:\n",
    "            # Add the invalid observation to the list\n",
    "            invalid_observations.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(invalid_observations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to PostgreSQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "could not connect to server: Connection timed out (0x0000274C/10060)\n\tIs the server running on host \"34.27.219.64\" and accepting\n\tTCP/IP connections on port 5432?\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "In  \u001b[0;34m[3]\u001b[0m:\nLine \u001b[0;34m2\u001b[0m:     connection = psycopg2.connect(host = \u001b[33m'\u001b[39;49;00m\u001b[33m34.27.219.64\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "File \u001b[0;34mC:\\Users\\eriks\\OneDrive\\Desktop\\ArcPyClone\\lib\\site-packages\\psycopg2\\__init__.py\u001b[0m, in \u001b[0;32mconnect\u001b[0m:\nLine \u001b[0;34m122\u001b[0m:   conn = _connect(dsn, connection_factory=connection_factory, **kwasync)\n",
      "\u001b[0;31mOperationalError\u001b[0m: could not connect to server: Connection timed out (0x0000274C/10060)\n\tIs the server running on host \"34.27.219.64\" and accepting\n\tTCP/IP connections on port 5432?\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Connect to postgresql database\n",
    "# Having some database connection issues now\n",
    "connection = psycopg2.connect(host = '34.47.216.64',\n",
    "                              port = '5432',\n",
    "                              database = 'lab2',\n",
    "                              user = 'postgres',\n",
    "                              password = 'student',\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature (stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\"stations.shp\")\n",
    "# fields I want from shapefile\n",
    "fields = [\"station\", \"date\", \"name\", \"max_tmpf\", \"min_tmpf\", \"Shape@WKT\"]\n",
    "\n",
    "# pscopg2 connection, replace *** and *** with your values\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"DROP TABLE IF EXISTS stations\")\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE stations (\n",
    "        id SERIAL,\n",
    "        station VARCHAR,\n",
    "        date VARCHAR,\n",
    "        name VARCHAR,\n",
    "        max_tmpf DOUBLE PRECISION,\n",
    "        min_tmpf DOUBLE PRECISION)\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT AddGeometryColumn('stations', 'geom', 4326, 'POINT', 2)\n",
    "\"\"\")\n",
    "\n",
    "# use arcpy to get attribute data, populate PostGIS using psycopg2\n",
    "with arcpy.da.SearchCursor(data, fields) as da_cursor:\n",
    "    for row in da_cursor:\n",
    "        wkt = row[5]\n",
    "        # this was tough - everything needs to be a string and text being inserted wrapped in '' including wkt\n",
    "        cursor.execute(\"INSERT INTO stations (station, date, name, max_tmpf, min_tmpf, geom) VALUES (%s, %s, %s, %s, %s, ST_GeomFromText(%s, 4326))\", (row[0], row[1], row[2], row[3], row[4], wkt))\n",
    "\n",
    "connection.commit()\n",
    "\n",
    "# Close database connection\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = ('elevation.shp')\n",
    "fields_points = ['pointid', 'grid_code', \"Shape@WKT\"]\n",
    "\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"DROP TABLE IF EXISTS elevation\")\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE elevation (\n",
    "        id SERIAL,\n",
    "        pointid INT,\n",
    "        grid_code INT)\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT AddGeometryColumn('elevation', 'geom', 4326, 'POINT', 2)\n",
    "\"\"\")\n",
    "\n",
    "# use arcpy to get attribute data, populate PostGIS using psycopg2\n",
    "with arcpy.da.SearchCursor(points, fields_points) as da_cursor:\n",
    "    for row in da_cursor:\n",
    "        wkt = row[2]\n",
    "        # this was tough - everything needs to be a string and text being inserted wrapped in '' including wkt\n",
    "        cursor.execute(\"INSERT INTO elevation (pointid, grid_code, geom) VALUES (%s, %s, ST_GeomFromText(%s, 4326))\", (row[0], row[1], wkt))\n",
    "\n",
    "connection.commit()\n",
    "\n",
    "# Close database connection\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stinkbug Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbugpoints = ('intersect_sbug_points.shp')\n",
    "sbug_fields = ['FID',\"CheckDate\",\"Adults\",\"Nymphs\"]\n",
    "\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"DROP TABLE IF EXISTS sbugpoints\")\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE sbugpoints (\n",
    "        id SERIAL,\n",
    "        FID INT,\n",
    "        CheckDate,\n",
    "        Adults INT,\n",
    "        Nymphs INT)\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT AddGeometryColumn('intersect_sbug_points', 'geom', 4326, 'POINT', 2)\n",
    "\"\"\")\n",
    "\n",
    "# use arcpy to get attribute data, populate PostGIS using psycopg2\n",
    "with arcpy.da.SearchCursor(sbugpoints, sbug_fields) as da_cursor:\n",
    "    for row in da_cursor:\n",
    "        wkt = row[2]\n",
    "        # this was tough - everything needs to be a string and text being inserted wrapped in '' including wkt\n",
    "        cursor.execute(\"INSERT INTO elevation (FID,CheckDate,Adults,Nymphs, geom) VALUES (%s, %s, ST_GeomFromText(%s, 4326))\", (row[0], row[1], row[2], row[3], wkt))\n",
    "\n",
    "connection.commit()\n",
    "\n",
    "# Close database connection\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Land Cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Could not successfully convert raster data to shapefile\n",
    "# Data not uploaded to database"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
